{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"datasetVersion","sourceId":14934656,"datasetId":9556886,"databundleVersionId":15802615},{"sourceType":"datasetVersion","sourceId":14924764,"datasetId":9549783,"databundleVersionId":15791762}],"dockerImageVersionId":31287,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install groq tenacity sentence-transformers scikit-learn tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T17:36:44.758370Z","iopub.execute_input":"2026-02-23T17:36:44.758879Z","iopub.status.idle":"2026-02-23T17:36:49.636128Z","shell.execute_reply.started":"2026-02-23T17:36:44.758853Z","shell.execute_reply":"2026-02-23T17:36:49.635348Z"}},"outputs":[{"name":"stdout","text":"Collecting groq\n  Downloading groq-1.0.0-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: tenacity in /usr/local/lib/python3.12/dist-packages (9.1.2)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.12.1)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq) (2.12.3)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\nRequirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\nRequirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (5.2.0)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cu126)\nRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\nRequirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.4.1)\nRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2026.1.4)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\nRequirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.5.4)\nRequirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (0.21.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (2.41.4)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq) (0.4.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\nRequirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.5)\nRequirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3.20)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\nRequirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.20.0->sentence-transformers) (8.3.1)\nDownloading groq-1.0.0-py3-none-any.whl (138 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m138.3/138.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: groq\nSuccessfully installed groq-1.0.0\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!git clone https://github.com/sooo66/semeval2026-task12-dataset.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T17:34:12.466663Z","iopub.execute_input":"2026-02-23T17:34:12.466911Z","iopub.status.idle":"2026-02-23T17:34:14.340582Z","shell.execute_reply.started":"2026-02-23T17:34:12.466885Z","shell.execute_reply":"2026-02-23T17:34:14.339881Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'semeval2026-task12-dataset'...\nremote: Enumerating objects: 69, done.\u001b[K\nremote: Counting objects: 100% (69/69), done.\u001b[K\nremote: Compressing objects: 100% (52/52), done.\u001b[K\nremote: Total 69 (delta 30), reused 51 (delta 15), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (69/69), 6.72 MiB | 21.36 MiB/s, done.\nResolving deltas: 100% (30/30), done.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import json\nimport os\n\n# ==========================================\n# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§\n# ==========================================\n# Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ù¾ÛŒØ´ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ (Ù‚Ø¯ÛŒÙ…ÛŒ Ùˆ Ø¬Ø¯ÛŒØ¯)\nOLD_PROCESSED_FILE = '/kaggle/input/datasets/daniyalghoreyshi/out111/train_data_enriched_with_cot.jsonl'\nRECENT_PROCESSED_FILE = '/kaggle/input/datasets/daniyalghoreyshi/newout/train_data_enriched_with_cot (4).jsonl'\n\n# Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ ØªÙ…ÛŒØ² Ø¨Ø±Ø§ÛŒ ÙØ§ÛŒÙ†â€ŒØªÛŒÙˆÙ†ÛŒÙ†Ú¯\nOUTPUT_FILE = 'train_data_ready_for_finetuning.jsonl'\n\n# ==========================================\n# Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø§Ø¯ØºØ§Ù…\n# ==========================================\nvalid_samples = {}\n\nprint(\"Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† Ùˆ Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡...\")\n\n# Ø®ÙˆØ§Ù†Ø¯Ù† Ù‡Ø± Ø¯Ùˆ ÙØ§ÛŒÙ„\nfor filepath in [OLD_PROCESSED_FILE, RECENT_PROCESSED_FILE]:\n    if os.path.exists(filepath):\n        print(f\"âœ… Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² ÙØ§ÛŒÙ„: {filepath}\")\n        with open(filepath, 'r', encoding='utf-8') as f:\n            for line in f:\n                if not line.strip(): \n                    continue\n                try:\n                    data = json.loads(line)\n                    # ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù†: ÙÙ‚Ø· Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¯Ø§Ø±Ù†Ø¯ Ùˆ Ù…ØªÙ† Ø¢Ù†â€ŒÙ‡Ø§ Ø®Ø·Ø§ Ù†ÛŒØ³Øª\n                    if data.get('reasoning') and data.get('reasoning') != \"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ø§Ø³ØªØ¯Ù„Ø§Ù„\":\n                        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ID Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† Ú©Ù„ÛŒØ¯ Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø§Ø¹Ø« Ù…ÛŒâ€ŒØ´ÙˆØ¯ \n                        # Ø§Ú¯Ø± ÛŒÚ© Ù†Ù…ÙˆÙ†Ù‡ Ø¯Ø± Ù‡Ø± Ø¯Ùˆ ÙØ§ÛŒÙ„ Ø¨ÙˆØ¯ØŒ Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± ØªÚ©Ø±Ø§Ø±Ú¯ÛŒØ±ÛŒ (Deduplication) Ø´ÙˆØ¯.\n                        valid_samples[data['id']] = data\n                except json.JSONDecodeError:\n                    continue\n    else:\n        print(f\"âš ï¸ Ø§Ø®Ø·Ø§Ø±: ÙØ§ÛŒÙ„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯ (Ù…Ø³ÛŒØ± Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯) -> {filepath}\")\n\n# ==========================================\n# Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ\n# ==========================================\nprint(f\"\\nØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ù„Ù…ØŒ Ø®Ø§Ù„Øµ Ùˆ Ø¨Ø¯ÙˆÙ† ØªÚ©Ø±Ø§Ø±: {len(valid_samples)}\")\nprint(f\"Ø¯Ø± Ø­Ø§Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ ({OUTPUT_FILE})...\")\n\nwith open(OUTPUT_FILE, 'w', encoding='utf-8') as out_file:\n    for sample in valid_samples.values():\n        out_file.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n\nprint(\"ğŸ‰ Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯!\")\nprint(\"Ø§Ú©Ù†ÙˆÙ† Ø¯ÛŒØªØ§Ø³Øª Ø´Ù…Ø§ Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¨Ø±Ø§ÛŒ Ù…Ø±Ø­Ù„Ù‡ Ø¢Ù…ÙˆØ²Ø´ (QLoRA Fine-Tuning) Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T17:44:05.873807Z","iopub.execute_input":"2026-02-23T17:44:05.874529Z","iopub.status.idle":"2026-02-23T17:44:06.014068Z","shell.execute_reply.started":"2026-02-23T17:44:05.874496Z","shell.execute_reply":"2026-02-23T17:44:06.013484Z"}},"outputs":[{"name":"stdout","text":"Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù† Ùˆ Ø¨Ø±Ø±Ø³ÛŒ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¯Ø§Ø¯Ù‡...\nâœ… Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² ÙØ§ÛŒÙ„: /kaggle/input/datasets/daniyalghoreyshi/out111/train_data_enriched_with_cot.jsonl\nâœ… Ø¯Ø± Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø² ÙØ§ÛŒÙ„: /kaggle/input/datasets/daniyalghoreyshi/newout/train_data_enriched_with_cot (4).jsonl\n\nØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ù„Ù…ØŒ Ø®Ø§Ù„Øµ Ùˆ Ø¨Ø¯ÙˆÙ† ØªÚ©Ø±Ø§Ø±: 1461\nØ¯Ø± Ø­Ø§Ù„ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ (train_data_ready_for_finetuning.jsonl)...\nğŸ‰ Ø¹Ù…Ù„ÛŒØ§Øª Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ù‡ Ù¾Ø§ÛŒØ§Ù† Ø±Ø³ÛŒØ¯!\nØ§Ú©Ù†ÙˆÙ† Ø¯ÛŒØªØ§Ø³Øª Ø´Ù…Ø§ Ú©Ø§Ù…Ù„Ø§Ù‹ Ø¨Ø±Ø§ÛŒ Ù…Ø±Ø­Ù„Ù‡ Ø¢Ù…ÙˆØ²Ø´ (QLoRA Fine-Tuning) Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# !pip install groq tenacity sentence-transformers scikit-learn tqdm\n\nimport json\nimport re\nimport os\nimport time\nfrom tqdm import tqdm\nfrom groq import Groq\nfrom tenacity import retry, wait_exponential, stop_after_attempt, retry_if_exception_type\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\n# ==========================================\n# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡ Ùˆ API\n# ==========================================\n# Ú©Ù„ÛŒØ¯ API Ø®ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ù‚Ø±Ø§Ø± Ø¯Ù‡ÛŒØ¯\nos.environ[\"GROQ_API_KEY\"] = \"\"\nclient = Groq()\n\n# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ù…Ø¯Ù„ Ø³Ø±ÛŒØ¹â€ŒØªØ± Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø®Ø·Ø§ÛŒ Rate Limit\nGROQ_MODEL = \"llama-3.1-8b-instant\"\n\n# Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ (Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø§Ù…)\nTRAIN_QUESTIONS_FILE = 'semeval2026-task12-dataset/train_data/questions.jsonl'\nTRAIN_DOCS_FILE = 'semeval2026-task12-dataset/train_data/docs.json'\n\n# Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø§Ø² Ù¾ÛŒØ´ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ (Ù‚Ø¯ÛŒÙ…ÛŒ Ùˆ Ø¬Ø¯ÛŒØ¯)\nOLD_PROCESSED_FILE = '/kaggle/input/datasets/daniyalghoreyshi/out111/train_data_enriched_with_cot.jsonl'\nRECENT_PROCESSED_FILE = '/kaggle/input/datasets/daniyalghoreyshi/newout/train_data_enriched_with_cot (4).jsonl' # Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ÛŒ Ú©Ù‡ Ø¨Ù‡ ØªØ§Ø²Ú¯ÛŒ Ø¢Ù¾Ù„ÙˆØ¯ Ú©Ø±Ø¯ÛŒØ¯\n\n# Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ ØªÙ…ÛŒØ²\nOUTPUT_FILE = 'train_data_enriched_with_cot_final.jsonl'\n\n# ==========================================\n# ØªÙˆØ§Ø¨Ø¹ Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ RAG\n# ==========================================\nprint(\"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Embedding...\")\nembedder = SentenceTransformer('BAAI/bge-large-en-v1.5')\n\ndef clean_text(text):\n    if not text or not isinstance(text, str): return \"\"\n    return re.sub(r'\\s+', ' ', text).strip()\n\ndef load_and_merge_data(questions_path, docs_path):\n    with open(docs_path, 'r', encoding='utf-8') as f:\n        docs_raw = json.load(f)\n    \n    docs_dict = {}\n    if isinstance(docs_raw, list):\n        for item in docs_raw:\n            if not isinstance(item, dict): continue\n            t_id = item.get(\"topic_id\")\n            if not t_id: continue\n            if t_id not in docs_dict: docs_dict[t_id] = []\n            \n            if \"docs\" in item or \"documents\" in item:\n                inner_docs = item.get(\"docs\", item.get(\"documents\", []))\n                for d in inner_docs:\n                    if isinstance(d, dict): docs_dict[t_id].append(d.get(\"text\", d.get(\"content\", d.get(\"doc\", \"\"))))\n                    elif isinstance(d, str): docs_dict[t_id].append(d)\n            else:\n                text_val = item.get(\"text\", item.get(\"content\", item.get(\"doc\", \"\")))\n                if text_val: docs_dict[t_id].append(text_val)\n\n    merged = []\n    with open(questions_path, 'r', encoding='utf-8') as f:\n        for line in f:\n            if not line.strip(): continue\n            q_item = json.loads(line.strip())\n            t_id = q_item.get(\"topic_id\")\n            related_docs = docs_dict.get(t_id, [])\n            cleaned_docs = [clean_text(doc) for doc in related_docs if doc]\n            \n            merged.append({\n                \"id\": q_item.get(\"id\"),\n                \"topic_id\": t_id,\n                \"target_event\": clean_text(q_item.get(\"target_event\")),\n                \"options\": {\n                    \"A\": clean_text(q_item.get(\"option_A\")),\n                    \"B\": clean_text(q_item.get(\"option_B\")),\n                    \"C\": clean_text(q_item.get(\"option_C\")),\n                    \"D\": clean_text(q_item.get(\"option_D\"))\n                },\n                \"golden_answer\": q_item.get(\"golden_answer\"),\n                \"context\": \" \".join(cleaned_docs)\n            })\n    return merged\n\ndef retrieve_relevant_context(sample, top_k=6):\n    context = sample['context']\n    sentences = re.split(r'(?<=[.!?])\\s+', context)\n    sentences = [s.strip() for s in sentences if len(s.strip()) > 20]\n    if not sentences: return \"\"\n\n    query = sample['target_event'] + \" \" + \" \".join(sample['options'].values())\n    sentence_embeddings = embedder.encode(sentences)\n    query_embedding = embedder.encode([query])\n\n    similarities = cosine_similarity(query_embedding, sentence_embeddings).flatten()\n    top_indices = similarities.argsort()[-top_k:]\n    return \" \".join([sentences[i] for i in sorted(top_indices)])\n\n# ==========================================\n# ØªØ§Ø¨Ø¹ ØªÙ…Ø§Ø³ Ø¨Ø§ Groq API Ù‡Ù…Ø±Ø§Ù‡ Ø¨Ø§ Retry Ø®ÙˆØ¯Ú©Ø§Ø± \n# ==========================================\n@retry(wait=wait_exponential(multiplier=1, min=4, max=60), stop=stop_after_attempt(5))\ndef generate_reasoning_with_groq(sample, filtered_context):\n    \n    golden_letters = sample['golden_answer'].split(',')\n    golden_texts = [sample['options'][letter.strip()] for letter in golden_letters]\n    golden_combined_text = \" AND \".join(golden_texts)\n    \n    prompt = f\"\"\"You are an expert logical reasoning AI. \nBased ONLY on the provided Context, explain logically why the following event:\n\"{golden_combined_text}\"\nis the direct cause of the Target Event:\n\"{sample['target_event']}\"\n\nContext: {filtered_context}\n\nCRITICAL RULES:\n1. DO NOT use the words \"Option\", \"Choice\", \"A\", \"B\", \"C\", or \"D\".\n2. Act as an independent analyst deducing the cause from the text.\n3. Keep it brief (2 to 3 sentences).\n4. Output ONLY the reasoning text.\"\"\"\n\n    chat_completion = client.chat.completions.create(\n        messages=[{\"role\": \"user\", \"content\": prompt}],\n        model=GROQ_MODEL,\n        temperature=0.1,\n        max_tokens=150,\n    )\n    \n    return chat_completion.choices[0].message.content.strip()\n\n# ==========================================\n# Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ\n# ==========================================\nprint(\"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ Ø®Ø§Ù…...\")\ntrain_dataset = load_and_merge_data(TRAIN_QUESTIONS_FILE, TRAIN_DOCS_FILE)\nprint(f\"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ: {len(train_dataset)}\")\n\nprint(\"Ø¯Ø± Ø­Ø§Ù„ ØªØ¬Ù…ÛŒØ¹ Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡ Ù‚Ø¨Ù„ÛŒ...\")\nvalid_samples = {}\n\n# Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ù‚Ø¯ÛŒÙ…ÛŒ Ùˆ ÙØ§ÛŒÙ„ Ø¬Ø¯ÛŒØ¯ Ùˆ ÙÛŒÙ„ØªØ± Ú©Ø±Ø¯Ù† Ø®Ø·Ø§Ø¯Ø§Ø±Ù‡Ø§\nfor filepath in [OLD_PROCESSED_FILE, RECENT_PROCESSED_FILE]:\n    if os.path.exists(filepath):\n        with open(filepath, 'r', encoding='utf-8') as f:\n            for line in f:\n                if not line.strip(): continue\n                data = json.loads(line)\n                # Ø´Ø±Ø· Ù…Ù‡Ù…: ÙÙ‚Ø· Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø¯Ø§Ø±Ù†Ø¯ Ùˆ Ù…ØªÙ† Ø¢Ù† Ø®Ø·Ø§ Ù†ÛŒØ³Øª Ø±Ø§ Ø¨Ù¾Ø°ÛŒØ±\n                if data.get('reasoning') and data.get('reasoning') != \"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ø§Ø³ØªØ¯Ù„Ø§Ù„\":\n                    valid_samples[data['id']] = data\n\nprint(f\"ØªØ¹Ø¯Ø§Ø¯ {len(valid_samples)} Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ùˆ Ø¨Ø¯ÙˆÙ† Ø®Ø·Ø§ Ø§Ø² Ù‚Ø¨Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯.\")\n\n# Ø§ÛŒØ¬Ø§Ø¯ ÙØ§ÛŒÙ„ Ù†Ù‡Ø§ÛŒÛŒ ØªÙ…ÛŒØ² Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ù„Ù… Ø¯Ø± Ø¢Ù†\nwith open(OUTPUT_FILE, 'w', encoding='utf-8') as f:\n    for s in valid_samples.values():\n        f.write(json.dumps(s, ensure_ascii=False) + '\\n')\n\nprint(\"Ø´Ø±ÙˆØ¹ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø®Ø·Ø§Ø¯Ø§Ø± Ùˆ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¨Ø§Ù‚ÛŒâ€ŒÙ…Ø§Ù†Ø¯Ù‡...\")\n\n# Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† ÙØ§ÛŒÙ„ Ø¨Ù‡ ØµÙˆØ±Øª Append Ø¨Ø±Ø§ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯\nwith open(OUTPUT_FILE, 'a', encoding='utf-8') as out_file:\n    for sample in tqdm(train_dataset, desc=\"Generating Reasoning\"):\n        \n        # Ø§Ú¯Ø± Ù†Ù…ÙˆÙ†Ù‡ Ø¯Ø± Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ù„Ù… ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªØŒ Ø§Ø² Ø¢Ù† Ø¹Ø¨ÙˆØ± Ú©Ù†\n        if sample['id'] in valid_samples:\n            continue\n            \n        smart_context = retrieve_relevant_context(sample, top_k=6)\n        \n        try:\n            reasoning = generate_reasoning_with_groq(sample, smart_context)\n            time.sleep(1.5) \n        except Exception as e:\n            print(f\"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ ID {sample['id']}: {e}\")\n            reasoning = \"Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ø§Ø³ØªØ¯Ù„Ø§Ù„\"\n            time.sleep(5)\n            \n        enriched_sample = sample.copy()\n        enriched_sample['reasoning'] = reasoning\n        enriched_sample['context'] = smart_context \n        \n        out_file.write(json.dumps(enriched_sample, ensure_ascii=False) + '\\n')\n        out_file.flush() \n\nprint(f\"\\nâœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙ…Ø§Ù… Ø´Ø¯. ÙØ§ÛŒÙ„ Ø¨ÛŒâ€ŒÙ†Ù‚Øµ Ùˆ Ù†Ù‡Ø§ÛŒÛŒ Ø¯Ø± {OUTPUT_FILE} Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-23T17:34:14.341954Z","iopub.execute_input":"2026-02-23T17:34:14.342381Z","iopub.status.idle":"2026-02-23T17:34:39.290189Z","shell.execute_reply.started":"2026-02-23T17:34:14.342351Z","shell.execute_reply":"2026-02-23T17:34:39.289104Z"}},"outputs":[{"name":"stdout","text":"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Embedding...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80fc0c70b541413ca8a21fea035e595c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9a1b013b022486b9ab71115d08551d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4df56c7bc36241f3bad082b982a8fb11"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"79e4805fc6e74c7898c2e0f670b94c5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/779 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e5010ddb8b8412c9a2aab0b9d2553de"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"360cda76b13d41898e26fb50d55cc7ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading weights:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84c8d6dba20942f09241abac283b7b93"}},"metadata":{}},{"name":"stderr","text":"\u001b[1mBertModel LOAD REPORT\u001b[0m from: BAAI/bge-large-en-v1.5\nKey                     | Status     |  | \n------------------------+------------+--+-\nembeddings.position_ids | UNEXPECTED |  | \n\n\u001b[3mNotes:\n- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\nWarning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f94e7167f9694657ab50e2b18541db12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f9ad2bb505d41dbb0b9e26165483590"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac353afa796341659bfca142f5d19a31"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"467e7b4db5c24c479e5fc58fc5d7a1d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"292cdfbdea3c4bf3a1cfe69a654e31df"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_55/3877672008.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# ==========================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ Embedding...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0membedder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'BAAI/bge-large-en-v1.5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[1;32m    365\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_hpu_graph_enabled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1369\u001b[0m                     \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m     def register_full_backward_pre_hook(\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    928\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrecurse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m                 \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m             \u001b[0mp_should_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1355\u001b[0m                         \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m                     )\n\u001b[0;32m-> 1357\u001b[0;31m                 return t.to(\n\u001b[0m\u001b[1;32m   1358\u001b[0m                     \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m                     \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mqueued_call\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_traceback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_queued_calls\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m                     \u001b[0mqueued_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m                     msg = (\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_check_capability\u001b[0;34m()\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_arch_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m     ):  # on ROCm we don't want this check\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m             \u001b[0mcapability\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_device_capability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0mmajor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcapability\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mdevice_count\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_cached_device_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m     \u001b[0;31m# bypass _device_count_nvml() if rocm (not supported)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m     \u001b[0mnvml_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_device_count_amdsmi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhip\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_device_count_nvml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDeviceCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnvml_count\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnvml_count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m     \u001b[0;31m# NB: Do not cache the device count prior to CUDA initialization, because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_device_count_nvml\u001b[0;34m()\u001b[0m\n\u001b[1;32m    982\u001b[0m             )\n\u001b[1;32m    983\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m             \u001b[0mraw_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_raw_device_count_nvml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraw_cnt\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mraw_cnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_raw_device_count_nvml\u001b[0;34m()\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0mnvml_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"libnvidia-ml.so.1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m     \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnvml_h\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnvmlInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrc\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't initialize NVML\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":3},{"cell_type":"code","source":"import os\nfrom groq import Groq\n\nos.environ[\"GROQ_API_KEY\"] = \"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\"\nclient = Groq()\n\n\ntry:\n    response = client.chat.completions.create(\n        messages=[{\"role\": \"user\", \"content\": \"Hello!\"}],\n        model=\"llama-3.3-70b-versatile\",\n        max_tokens=10\n    )\n    print(\"âœ… Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Groq Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø±Ù‚Ø±Ø§Ø± Ø´Ø¯!\")\nexcept Exception as e:\n    print(f\"âŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¯Ù‚ÛŒÙ‚ Ø®Ø·Ø§: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-23T17:39:26.884270Z","iopub.execute_input":"2026-02-23T17:39:26.884875Z","iopub.status.idle":"2026-02-23T17:39:27.000289Z","shell.execute_reply.started":"2026-02-23T17:39:26.884848Z","shell.execute_reply":"2026-02-23T17:39:26.999692Z"}},"outputs":[{"name":"stdout","text":"âŒ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¯Ù‚ÛŒÙ‚ Ø®Ø·Ø§: Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}